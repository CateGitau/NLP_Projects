{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for big files when commiting to github https://stackoverflow.com/questions/32953238/how-can-i-ignore-big-files-and-push-to-git-repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_names = ['sentiment', 'id', 'date', 'query_string', 'user', 'text']\n",
    "data_path = '/home/cate/streamlit-projects/sentiment140/training.1600000.processed.noemoticon.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sentiment                                               text\n191614           0  Yeah I Hope So!! Its To Hard To See Him N Just...\n1149676          4  And a perfect rainbow never seemed so dull. An...\n128223           0                 My tummy hurts and I'm dehydrated \n767517           0  No sooner than I leave the office with the hop...\n180436           0  A Friday night down the drain! Damn you 8 am m...\n"
    }
   ],
   "source": [
    "tweet_data = pd.read_csv(data_path, header = None, names = col_names, encoding=\"ISO-8859-1\",engine = 'python' ).sample(frac = 1) #shaffles the data\n",
    "tweet_data = tweet_data[['sentiment', 'text']] #disregard other columns\n",
    "print(tweet_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "allowed_chars = ' AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz0123456789~`!@#$%^&*()-=_+[]{}|;:\",./<>?'\n",
    "punct = '!?,.@#'\n",
    "maxlen = 280\n",
    "\n",
    "def preprocess(text):\n",
    "    return ''.join([' ' + char + ' ' if char in punct else char for char in [char for char in re.sub(r'http\\S+', 'http', text, flags=re.MULTILINE) if char in allowed_chars]])[:maxlen]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flair requires a specific format for the data to be in; it wants three CSV’s that look like:\n",
    "\n",
    "\\__label__ < LABEL>      < TEXT>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the preprocessing function\n",
    "tweet_data['text'] = tweet_data['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put __label__ in front of each sentiment\n",
    "tweet_data['sentiment'] = '__label__' + tweet_data['sentiment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data\n",
    "import os\n",
    "\n",
    "# Create directory for saving data if it does not already exist\n",
    "data_dir = '/home/cate/streamlit-projects/twitter_sentiment/processed-data/'\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "# Save a percentage of the data (you could also only load a fraction of the data instead)\n",
    "amount = 0.125\n",
    "\n",
    "tweet_data.iloc[0:int(len(tweet_data)*0.8*amount)].to_csv(data_dir + '/train.csv', sep='\\t', index=False, header=False)\n",
    "tweet_data.iloc[int(len(tweet_data)*0.8*amount):int(len(tweet_data)*0.9*amount)].to_csv(data_dir + '/test.csv', sep='\\t', index=False, header=False)\n",
    "tweet_data.iloc[int(len(tweet_data)*0.9*amount):int(len(tweet_data)*1.0*amount)].to_csv(data_dir + '/dev.csv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "In this particular example we will use **Flair** This is a popular machine learning library for state-of-the-art NLP\n",
    "\n",
    "\n",
    "Flair tutorials -> https://github.com/flairNLP/flair/tree/master/resources/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data \n",
    "Loading the test, train and dev sets using Flair's NLPTaskDataFetcher class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2020-05-11 15:25:34,306 Reading data from /home/cate/streamlit-projects/twitter_sentiment/processed-data\n2020-05-11 15:25:34,307 Train: /home/cate/streamlit-projects/twitter_sentiment/processed-data/train.csv\n2020-05-11 15:25:34,307 Dev: /home/cate/streamlit-projects/twitter_sentiment/processed-data/dev.csv\n2020-05-11 15:25:34,308 Test: /home/cate/streamlit-projects/twitter_sentiment/processed-data/test.csv\n"
    }
   ],
   "source": [
    "from flair.datasets import ClassificationCorpus\n",
    "from pathlib import Path\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus = ClassificationCorpus(Path(data_dir),\n",
    "                                      test_file='test.csv',\n",
    "                                      dev_file='dev.csv',\n",
    "                                      train_file='train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2020-05-11 15:25:36,721 Computing label dictionary. Progress:\n100%|██████████| 160000/160000 [00:33<00:00, 4836.88it/s]2020-05-11 15:26:09,947 [b'0', b'4']\n\n"
    }
   ],
   "source": [
    "# a label dictionary to hold all the labels assigned to the text in the corpus\n",
    "\n",
    "label_dict = corpus.make_label_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Flair's provided GloVe embeddings\n",
    "\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "\n",
    "word_embeddings = [WordEmbeddings('glove'),\n",
    "# these are extra word embeddings provided by Flair for superior results\n",
    "#                    FlairEmbeddings('news-forward'),\n",
    "#                    FlairEmbeddings('news-backward')\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the embeddings\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "00/5000 - loss 0.64147999 - samples/sec: 130.88\n2020-05-11 15:42:33,072 epoch 1 - iter 3500/5000 - loss 0.63742109 - samples/sec: 128.95\n2020-05-11 15:44:33,132 epoch 1 - iter 4000/5000 - loss 0.63288279 - samples/sec: 139.41\n2020-05-11 15:46:44,634 epoch 1 - iter 4500/5000 - loss 0.62962353 - samples/sec: 126.95\n2020-05-11 15:48:38,764 ----------------------------------------------------------------------------------------------------\n2020-05-11 15:48:38,766 EPOCH 1 done: loss 0.6263 - lr 0.1000\n2020-05-11 15:49:03,715 DEV : loss 0.5499045848846436 - score 0.7266\n2020-05-11 15:49:07,240 BAD EPOCHS (no improvement): 0\n2020-05-11 15:49:11,766 ----------------------------------------------------------------------------------------------------\n2020-05-11 15:49:12,288 epoch 2 - iter 0/5000 - loss 0.65329576 - samples/sec: 55976.48\n2020-05-11 15:51:03,200 epoch 2 - iter 500/5000 - loss 0.59178817 - samples/sec: 150.89\n2020-05-11 15:53:01,180 epoch 2 - iter 1000/5000 - loss 0.59182155 - samples/sec: 141.46\n2020-05-11 15:54:56,888 epoch 2 - iter 1500/5000 - loss 0.58805633 - samples/sec: 144.13\n2020-05-11 15:57:01,558 epoch 2 - iter 2000/5000 - loss 0.58874496 - samples/sec: 133.63\n2020-05-11 15:59:00,746 epoch 2 - iter 2500/5000 - loss 0.58651213 - samples/sec: 140.43\n2020-05-11 16:01:00,898 epoch 2 - iter 3000/5000 - loss 0.58547585 - samples/sec: 138.90\n2020-05-11 16:02:55,877 epoch 2 - iter 3500/5000 - loss 0.58488301 - samples/sec: 145.34\n2020-05-11 16:04:53,363 epoch 2 - iter 4000/5000 - loss 0.58420316 - samples/sec: 142.06\n2020-05-11 16:06:51,597 epoch 2 - iter 4500/5000 - loss 0.58299997 - samples/sec: 141.13\n2020-05-11 16:09:06,323 ----------------------------------------------------------------------------------------------------\n2020-05-11 16:09:06,325 EPOCH 2 done: loss 0.5824 - lr 0.1000\n2020-05-11 16:09:36,753 DEV : loss 0.5265305042266846 - score 0.7409\n2020-05-11 16:09:41,855 BAD EPOCHS (no improvement): 0\n2020-05-11 16:09:47,824 ----------------------------------------------------------------------------------------------------\n2020-05-11 16:09:48,500 epoch 3 - iter 0/5000 - loss 0.38411668 - samples/sec: 42880.02\n2020-05-11 16:11:57,113 epoch 3 - iter 500/5000 - loss 0.57300013 - samples/sec: 129.60\n2020-05-11 16:14:15,202 epoch 3 - iter 1000/5000 - loss 0.57298886 - samples/sec: 120.91\n2020-05-11 16:16:43,409 epoch 3 - iter 1500/5000 - loss 0.57239072 - samples/sec: 112.40\n2020-05-11 16:18:42,852 epoch 3 - iter 2000/5000 - loss 0.57158711 - samples/sec: 139.54\n2020-05-11 16:21:04,993 epoch 3 - iter 2500/5000 - loss 0.57127488 - samples/sec: 117.54\n2020-05-11 16:23:21,027 epoch 3 - iter 3000/5000 - loss 0.57147959 - samples/sec: 122.91\n2020-05-11 16:25:39,470 epoch 3 - iter 3500/5000 - loss 0.57058473 - samples/sec: 120.47\n2020-05-11 16:27:56,033 epoch 3 - iter 4000/5000 - loss 0.56928047 - samples/sec: 121.90\n2020-05-11 16:30:12,895 epoch 3 - iter 4500/5000 - loss 0.56864243 - samples/sec: 122.16\n2020-05-11 16:32:27,473 ----------------------------------------------------------------------------------------------------\n2020-05-11 16:32:27,475 EPOCH 3 done: loss 0.5686 - lr 0.1000\n2020-05-11 16:32:59,846 DEV : loss 0.5178809762001038 - score 0.7448\n2020-05-11 16:33:04,959 BAD EPOCHS (no improvement): 0\n2020-05-11 16:33:10,820 ----------------------------------------------------------------------------------------------------\n2020-05-11 16:33:11,582 epoch 4 - iter 0/5000 - loss 0.52302098 - samples/sec: 41371.70\n2020-05-11 16:35:28,316 epoch 4 - iter 500/5000 - loss 0.56581245 - samples/sec: 122.18\n2020-05-11 16:37:44,566 epoch 4 - iter 1000/5000 - loss 0.56071821 - samples/sec: 122.42\n2020-05-11 17:34:06,599 epoch 4 - iter 1500/5000 - loss 0.56305462 - samples/sec: 4.74\n2020-05-11 17:36:17,615 epoch 4 - iter 2000/5000 - loss 0.56325483 - samples/sec: 127.15\n2020-05-11 17:38:24,909 epoch 4 - iter 2500/5000 - loss 0.56305513 - samples/sec: 131.26\n2020-05-11 17:40:23,362 epoch 4 - iter 3000/5000 - loss 0.56140863 - samples/sec: 140.68\n2020-05-11 17:42:29,454 epoch 4 - iter 3500/5000 - loss 0.56080008 - samples/sec: 132.21\n2020-05-11 17:44:34,015 epoch 4 - iter 4000/5000 - loss 0.56021303 - samples/sec: 134.07\n2020-05-11 17:46:32,981 epoch 4 - iter 4500/5000 - loss 0.55949015 - samples/sec: 140.24\n2020-05-11 17:48:34,496 ----------------------------------------------------------------------------------------------------\n2020-05-11 17:48:34,497 EPOCH 4 done: loss 0.5592 - lr 0.1000\n2020-05-11 17:49:03,827 DEV : loss 0.5046098232269287 - score 0.7527\n2020-05-11 17:49:08,343 BAD EPOCHS (no improvement): 0\n2020-05-11 17:49:13,351 ----------------------------------------------------------------------------------------------------\n2020-05-11 17:49:14,029 epoch 5 - iter 0/5000 - loss 0.60640615 - samples/sec: 46373.03\n2020-05-11 17:51:10,057 epoch 5 - iter 500/5000 - loss 0.55248809 - samples/sec: 143.30\n2020-05-11 17:53:10,606 epoch 5 - iter 1000/5000 - loss 0.55238491 - samples/sec: 138.16\n2020-05-11 17:55:07,186 epoch 5 - iter 1500/5000 - loss 0.55247639 - samples/sec: 143.16\n2020-05-11 17:57:10,477 epoch 5 - iter 2000/5000 - loss 0.55363260 - samples/sec: 135.11\n2020-05-11 17:59:07,696 epoch 5 - iter 2500/5000 - loss 0.55329357 - samples/sec: 142.07\n2020-05-11 18:01:09,411 epoch 5 - iter 3000/5000 - loss 0.55276553 - samples/sec: 137.10\n2020-05-11 18:02:56,680 epoch 5 - iter 3500/5000 - loss 0.55202021 - samples/sec: 155.74\n2020-05-11 18:04:33,203 epoch 5 - iter 4000/5000 - loss 0.55120847 - samples/sec: 172.97\n2020-05-11 18:06:06,948 epoch 5 - iter 4500/5000 - loss 0.55097974 - samples/sec: 179.61\n2020-05-11 18:07:40,869 ----------------------------------------------------------------------------------------------------\n2020-05-11 18:07:40,872 EPOCH 5 done: loss 0.5511 - lr 0.1000\n2020-05-11 18:08:01,845 DEV : loss 0.4964134395122528 - score 0.7581\n2020-05-11 18:08:05,219 BAD EPOCHS (no improvement): 0\n2020-05-11 18:08:09,249 ----------------------------------------------------------------------------------------------------\n2020-05-11 18:08:09,721 epoch 6 - iter 0/5000 - loss 0.49044374 - samples/sec: 72758.80\n2020-05-11 18:09:48,275 epoch 6 - iter 500/5000 - loss 0.54627570 - samples/sec: 170.19\n2020-05-11 18:11:21,148 epoch 6 - iter 1000/5000 - loss 0.54731774 - samples/sec: 179.55\n2020-05-11 18:12:55,373 epoch 6 - iter 1500/5000 - loss 0.54614980 - samples/sec: 177.60\n2020-05-11 18:14:31,011 epoch 6 - iter 2000/5000 - loss 0.54670046 - samples/sec: 175.66\n2020-05-11 18:16:02,218 epoch 6 - iter 2500/5000 - loss 0.54791811 - samples/sec: 182.65\n2020-05-11 18:17:38,988 epoch 6 - iter 3000/5000 - loss 0.54824853 - samples/sec: 173.05\n2020-05-11 18:19:16,399 epoch 6 - iter 3500/5000 - loss 0.54810636 - samples/sec: 172.57\n2020-05-11 18:20:50,852 epoch 6 - iter 4000/5000 - loss 0.54716637 - samples/sec: 176.87\n2020-05-11 18:22:26,560 epoch 6 - iter 4500/5000 - loss 0.54731893 - samples/sec: 175.12\n2020-05-11 18:24:01,277 ----------------------------------------------------------------------------------------------------\n2020-05-11 18:24:01,278 EPOCH 6 done: loss 0.5472 - lr 0.1000\n2020-05-11 18:24:21,846 DEV : loss 0.49370747804641724 - score 0.7591\n2020-05-11 18:24:24,890 BAD EPOCHS (no improvement): 0\n2020-05-11 18:24:28,840 ----------------------------------------------------------------------------------------------------\n2020-05-11 18:24:29,290 epoch 7 - iter 0/5000 - loss 0.43687695 - samples/sec: 75314.96\n2020-05-11 18:26:03,168 epoch 7 - iter 500/5000 - loss 0.54467402 - samples/sec: 178.12\n2020-05-11 18:27:36,826 epoch 7 - iter 1000/5000 - loss 0.54397509 - samples/sec: 177.97\n2020-05-11 18:29:12,830 epoch 7 - iter 1500/5000 - loss 0.54437279 - samples/sec: 174.60\n2020-05-11 18:30:43,741 epoch 7 - iter 2000/5000 - loss 0.54436930 - samples/sec: 183.45\n2020-05-11 18:32:18,663 epoch 7 - iter 2500/5000 - loss 0.54412562 - samples/sec: 176.79\n2020-05-11 18:33:53,963 epoch 7 - iter 3000/5000 - loss 0.54189701 - samples/sec: 175.28\n2020-05-11 18:35:29,709 epoch 7 - iter 3500/5000 - loss 0.54155236 - samples/sec: 174.60\n2020-05-11 18:37:05,208 epoch 7 - iter 4000/5000 - loss 0.54073585 - samples/sec: 175.79\n2020-05-11 18:38:38,457 epoch 7 - iter 4500/5000 - loss 0.54048306 - samples/sec: 179.06\n2020-05-11 18:40:15,375 ----------------------------------------------------------------------------------------------------\n2020-05-11 18:40:15,375 EPOCH 7 done: loss 0.5401 - lr 0.1000\n2020-05-11 18:40:36,319 DEV : loss 0.48561176657676697 - score 0.7692\n2020-05-11 18:40:39,638 BAD EPOCHS (no improvement): 0\n2020-05-11 18:40:43,698 ----------------------------------------------------------------------------------------------------\n2020-05-11 18:40:44,133 epoch 8 - iter 0/5000 - loss 0.52875906 - samples/sec: 82433.50\n2020-05-11 18:42:19,909 epoch 8 - iter 500/5000 - loss 0.54333149 - samples/sec: 174.94\n2020-05-11 18:43:52,136 epoch 8 - iter 1000/5000 - loss 0.53775357 - samples/sec: 181.06\n2020-05-11 18:45:30,717 epoch 8 - iter 1500/5000 - loss 0.53887838 - samples/sec: 170.61\n2020-05-11 18:47:02,859 epoch 8 - iter 2000/5000 - loss 0.53821836 - samples/sec: 181.17\n2020-05-11 18:48:35,932 epoch 8 - iter 2500/5000 - loss 0.53837022 - samples/sec: 179.36\n2020-05-11 18:50:08,417 epoch 8 - iter 3000/5000 - loss 0.53796117 - samples/sec: 181.06\n2020-05-11 18:51:43,568 epoch 8 - iter 3500/5000 - loss 0.53855751 - samples/sec: 175.47\n2020-05-11 18:53:20,724 epoch 8 - iter 4000/5000 - loss 0.53862677 - samples/sec: 172.00\n2020-05-11 18:54:53,772 epoch 8 - iter 4500/5000 - loss 0.53804942 - samples/sec: 179.82\n2020-05-11 18:56:26,824 ----------------------------------------------------------------------------------------------------\n2020-05-11 18:56:26,824 EPOCH 8 done: loss 0.5378 - lr 0.1000\n2020-05-11 18:56:47,322 DEV : loss 0.4975057542324066 - score 0.7607\n2020-05-11 18:56:50,782 BAD EPOCHS (no improvement): 1\n2020-05-11 18:56:50,874 ----------------------------------------------------------------------------------------------------\n2020-05-11 18:56:51,410 epoch 9 - iter 0/5000 - loss 0.43052381 - samples/sec: 55541.01\n2020-05-11 18:58:28,155 epoch 9 - iter 500/5000 - loss 0.53657551 - samples/sec: 172.86\n2020-05-11 19:00:04,968 epoch 9 - iter 1000/5000 - loss 0.53841165 - samples/sec: 172.83\n2020-05-11 19:01:42,464 epoch 9 - iter 1500/5000 - loss 0.53772241 - samples/sec: 171.94\n2020-05-11 19:03:22,653 epoch 9 - iter 2000/5000 - loss 0.53658293 - samples/sec: 166.85\n2020-05-11 19:04:59,521 epoch 9 - iter 2500/5000 - loss 0.53554960 - samples/sec: 172.80\n2020-05-11 19:06:33,171 epoch 9 - iter 3000/5000 - loss 0.53613899 - samples/sec: 179.11\n2020-05-11 19:08:06,566 epoch 9 - iter 3500/5000 - loss 0.53636131 - samples/sec: 178.36\n2020-05-11 19:09:39,980 epoch 9 - iter 4000/5000 - loss 0.53573330 - samples/sec: 178.86\n2020-05-11 19:11:16,882 epoch 9 - iter 4500/5000 - loss 0.53464505 - samples/sec: 173.61\n2020-05-11 19:12:52,711 ----------------------------------------------------------------------------------------------------\n2020-05-11 19:12:52,713 EPOCH 9 done: loss 0.5342 - lr 0.1000\n2020-05-11 19:13:13,306 DEV : loss 0.47085386514663696 - score 0.7751\n2020-05-11 19:13:16,720 BAD EPOCHS (no improvement): 0\n2020-05-11 19:13:21,076 ----------------------------------------------------------------------------------------------------\n2020-05-11 19:13:21,569 epoch 10 - iter 0/5000 - loss 0.64653075 - samples/sec: 68723.31\n2020-05-11 19:14:56,948 epoch 10 - iter 500/5000 - loss 0.53616822 - samples/sec: 175.39\n2020-05-11 19:16:30,374 epoch 10 - iter 1000/5000 - loss 0.53441921 - samples/sec: 178.78\n2020-05-11 19:18:06,485 epoch 10 - iter 1500/5000 - loss 0.52962380 - samples/sec: 174.65\n2020-05-11 19:19:52,356 epoch 10 - iter 2000/5000 - loss 0.52988595 - samples/sec: 157.76\n2020-05-11 19:22:01,881 epoch 10 - iter 2500/5000 - loss 0.53108005 - samples/sec: 128.67\n2020-05-11 19:24:13,329 epoch 10 - iter 3000/5000 - loss 0.53140275 - samples/sec: 127.21\n2020-05-11 19:26:25,805 epoch 10 - iter 3500/5000 - loss 0.53067636 - samples/sec: 126.06\n2020-05-11 19:28:37,400 epoch 10 - iter 4000/5000 - loss 0.53025049 - samples/sec: 126.60\n2020-05-11 19:30:50,308 epoch 10 - iter 4500/5000 - loss 0.53027404 - samples/sec: 126.07\n2020-05-11 19:32:59,308 ----------------------------------------------------------------------------------------------------\n2020-05-11 19:32:59,309 EPOCH 10 done: loss 0.5306 - lr 0.1000\n2020-05-11 19:33:24,041 DEV : loss 0.4763081967830658 - score 0.773\n2020-05-11 19:33:27,625 BAD EPOCHS (no improvement): 1\n2020-05-11 19:33:27,722 ----------------------------------------------------------------------------------------------------\n2020-05-11 19:33:28,211 epoch 11 - iter 0/5000 - loss 0.41785145 - samples/sec: 70656.90\n2020-05-11 19:35:42,439 epoch 11 - iter 500/5000 - loss 0.52731903 - samples/sec: 124.40\n2020-05-11 19:37:45,664 epoch 11 - iter 1000/5000 - loss 0.52652100 - samples/sec: 136.00\n2020-05-11 19:39:54,629 epoch 11 - iter 1500/5000 - loss 0.52913020 - samples/sec: 129.32\n2020-05-11 19:42:04,696 epoch 11 - iter 2000/5000 - loss 0.52790441 - samples/sec: 128.15\n2020-05-11 19:44:20,797 epoch 11 - iter 2500/5000 - loss 0.52841539 - samples/sec: 122.49\n2020-05-11 19:46:14,297 epoch 11 - iter 3000/5000 - loss 0.52841543 - samples/sec: 147.79\n2020-05-11 19:47:49,855 epoch 11 - iter 3500/5000 - loss 0.52918726 - samples/sec: 175.02\n2020-05-11 19:49:29,545 epoch 11 - iter 4000/5000 - loss 0.52856686 - samples/sec: 168.18\n2020-05-11 19:51:15,082 epoch 11 - iter 4500/5000 - loss 0.52812051 - samples/sec: 158.31\n2020-05-11 19:53:31,498 ----------------------------------------------------------------------------------------------------\n2020-05-11 19:53:31,498 EPOCH 11 done: loss 0.5281 - lr 0.1000\n2020-05-11 19:53:57,439 DEV : loss 0.4737057089805603 - score 0.777\n2020-05-11 19:54:00,855 BAD EPOCHS (no improvement): 0\n2020-05-11 19:54:05,493 ----------------------------------------------------------------------------------------------------\n2020-05-11 19:54:06,091 epoch 12 - iter 0/5000 - loss 0.50054801 - samples/sec: 55434.11\n2020-05-11 19:55:52,039 epoch 12 - iter 500/5000 - loss 0.52858749 - samples/sec: 158.32\n2020-05-11 19:57:33,290 epoch 12 - iter 1000/5000 - loss 0.52822525 - samples/sec: 166.04\n2020-05-11 19:59:25,380 epoch 12 - iter 1500/5000 - loss 0.52774368 - samples/sec: 149.39\n2020-05-11 20:01:20,797 epoch 12 - iter 2000/5000 - loss 0.52755216 - samples/sec: 144.75\n2020-05-11 20:03:12,096 epoch 12 - iter 2500/5000 - loss 0.52772289 - samples/sec: 150.62\n2020-05-11 20:05:04,391 epoch 12 - iter 3000/5000 - loss 0.52683020 - samples/sec: 149.08\n2020-05-11 20:06:49,151 epoch 12 - iter 3500/5000 - loss 0.52630192 - samples/sec: 159.89\n2020-05-11 20:08:39,740 epoch 12 - iter 4000/5000 - loss 0.52568138 - samples/sec: 151.53\n2020-05-11 20:10:18,937 epoch 12 - iter 4500/5000 - loss 0.52520846 - samples/sec: 169.21\n2020-05-11 20:12:04,470 ----------------------------------------------------------------------------------------------------\n2020-05-11 20:12:04,472 EPOCH 12 done: loss 0.5256 - lr 0.1000\n2020-05-11 20:12:28,441 DEV : loss 0.466677725315094 - score 0.7788\n2020-05-11 20:12:32,006 BAD EPOCHS (no improvement): 0\n2020-05-11 20:12:36,430 ----------------------------------------------------------------------------------------------------\n2020-05-11 20:12:36,909 epoch 13 - iter 0/5000 - loss 0.67581463 - samples/sec: 71772.57\n2020-05-11 20:14:26,489 epoch 13 - iter 500/5000 - loss 0.52240189 - samples/sec: 152.75\n2020-05-11 20:16:18,527 epoch 13 - iter 1000/5000 - loss 0.52359876 - samples/sec: 149.42\n2020-05-11 20:18:00,751 epoch 13 - iter 1500/5000 - loss 0.52416045 - samples/sec: 163.96\n2020-05-11 20:19:46,406 epoch 13 - iter 2000/5000 - loss 0.52287719 - samples/sec: 158.76\n2020-05-11 20:21:48,507 epoch 13 - iter 2500/5000 - loss 0.52250198 - samples/sec: 136.68\n2020-05-11 20:23:43,623 epoch 13 - iter 3000/5000 - loss 0.52269445 - samples/sec: 145.48\n2020-05-11 20:25:19,384 epoch 13 - iter 3500/5000 - loss 0.52202835 - samples/sec: 174.64\n2020-05-11 20:26:53,590 epoch 13 - iter 4000/5000 - loss 0.52266854 - samples/sec: 178.53\n2020-05-11 20:29:09,076 epoch 13 - iter 4500/5000 - loss 0.52243660 - samples/sec: 123.12\n2020-05-11 20:30:53,415 ----------------------------------------------------------------------------------------------------\n2020-05-11 20:30:53,416 EPOCH 13 done: loss 0.5227 - lr 0.1000\n2020-05-11 20:31:14,731 DEV : loss 0.4716951549053192 - score 0.7761\n2020-05-11 20:31:18,001 BAD EPOCHS (no improvement): 1\n2020-05-11 20:31:18,095 ----------------------------------------------------------------------------------------------------\n2020-05-11 20:31:18,617 epoch 14 - iter 0/5000 - loss 0.51263773 - samples/sec: 80548.94\n2020-05-11 20:32:58,362 epoch 14 - iter 500/5000 - loss 0.51521825 - samples/sec: 167.86\n2020-05-11 20:34:36,012 epoch 14 - iter 1000/5000 - loss 0.51895369 - samples/sec: 171.15\n2020-05-11 20:36:13,947 epoch 14 - iter 1500/5000 - loss 0.51974741 - samples/sec: 171.42\n2020-05-11 20:37:50,599 epoch 14 - iter 2000/5000 - loss 0.52097955 - samples/sec: 173.03\n2020-05-11 20:39:31,264 epoch 14 - iter 2500/5000 - loss 0.52051618 - samples/sec: 166.04\n2020-05-11 20:41:18,266 epoch 14 - iter 3000/5000 - loss 0.52009193 - samples/sec: 156.51\n2020-05-11 20:43:31,150 epoch 14 - iter 3500/5000 - loss 0.52045083 - samples/sec: 125.41\n2020-05-11 20:46:05,183 epoch 14 - iter 4000/5000 - loss 0.52079616 - samples/sec: 108.04\n2020-05-11 20:48:15,699 epoch 14 - iter 4500/5000 - loss 0.52093466 - samples/sec: 127.93\n2020-05-11 20:50:24,317 ----------------------------------------------------------------------------------------------------\n2020-05-11 20:50:24,318 EPOCH 14 done: loss 0.5211 - lr 0.1000\n2020-05-11 20:50:52,930 DEV : loss 0.47066450119018555 - score 0.7742\n2020-05-11 20:50:56,947 BAD EPOCHS (no improvement): 2\n2020-05-11 20:50:56,966 ----------------------------------------------------------------------------------------------------\n2020-05-11 20:50:57,565 epoch 15 - iter 0/5000 - loss 0.42890212 - samples/sec: 46736.15\n2020-05-11 20:53:24,814 epoch 15 - iter 500/5000 - loss 0.52113374 - samples/sec: 113.34\n2020-05-11 20:55:31,374 epoch 15 - iter 1000/5000 - loss 0.52097767 - samples/sec: 131.87\n2020-05-11 20:57:36,200 epoch 15 - iter 1500/5000 - loss 0.51770854 - samples/sec: 134.29\n2020-05-11 20:59:43,297 epoch 15 - iter 2000/5000 - loss 0.51855749 - samples/sec: 131.56\n2020-05-11 21:01:54,945 epoch 15 - iter 2500/5000 - loss 0.51854489 - samples/sec: 126.64\n2020-05-11 21:04:20,902 epoch 15 - iter 3000/5000 - loss 0.51898449 - samples/sec: 114.64\n2020-05-11 21:06:44,378 epoch 15 - iter 3500/5000 - loss 0.51835660 - samples/sec: 116.81\n2020-05-11 21:09:18,680 epoch 15 - iter 4000/5000 - loss 0.51969582 - samples/sec: 108.05\n2020-05-11 21:11:53,086 epoch 15 - iter 4500/5000 - loss 0.51915815 - samples/sec: 107.84\n2020-05-11 21:14:23,852 ----------------------------------------------------------------------------------------------------\n2020-05-11 21:14:24,033 EPOCH 15 done: loss 0.5181 - lr 0.1000\n2020-05-11 21:15:01,115 DEV : loss 0.4647756814956665 - score 0.7794\n2020-05-11 21:15:06,481 BAD EPOCHS (no improvement): 0\n2020-05-11 21:15:16,381 ----------------------------------------------------------------------------------------------------\n2020-05-11 21:15:16,382 Testing using best model ...\n2020-05-11 21:15:16,385 loading file model-saves/best-model.pt\n2020-05-11 21:15:51,139 0.7863\t0.7863\t0.7863\n2020-05-11 21:15:51,141 \nMICRO_AVG: acc 0.6479 - f1-score 0.7863\nMACRO_AVG: acc 0.6479 - f1-score 0.78635\n0          tp: 7763 - fp: 2049 - fn: 2224 - tn: 7964 - precision: 0.7912 - recall: 0.7773 - accuracy: 0.6450 - f1-score: 0.7842\n4          tp: 7964 - fp: 2224 - fn: 2049 - tn: 7763 - precision: 0.7817 - recall: 0.7954 - accuracy: 0.6508 - f1-score: 0.7885\n2020-05-11 21:15:51,142 ----------------------------------------------------------------------------------------------------\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'test_score': 0.7863,\n 'dev_score_history': [0.7266,\n  0.7409,\n  0.7448,\n  0.7527,\n  0.7581,\n  0.7591,\n  0.7692,\n  0.7607,\n  0.7751,\n  0.773,\n  0.777,\n  0.7788,\n  0.7761,\n  0.7742,\n  0.7794],\n 'train_loss_history': [0.6262768354952335,\n  0.5823872073888778,\n  0.5685568423330783,\n  0.5591698117792606,\n  0.5510672243237495,\n  0.5471562961041927,\n  0.5401257211267948,\n  0.5378082399129868,\n  0.5341873123556375,\n  0.5305983853459358,\n  0.5281305697679519,\n  0.5256288422375918,\n  0.5227320364534855,\n  0.521134237754345,\n  0.5181407861113548],\n 'dev_loss_history': [tensor(0.5499),\n  tensor(0.5265),\n  tensor(0.5179),\n  tensor(0.5046),\n  tensor(0.4964),\n  tensor(0.4937),\n  tensor(0.4856),\n  tensor(0.4975),\n  tensor(0.4709),\n  tensor(0.4763),\n  tensor(0.4737),\n  tensor(0.4667),\n  tensor(0.4717),\n  tensor(0.4707),\n  tensor(0.4648)]}"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "#train the model\n",
    "trainer.train('model-saves',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=8,\n",
    "              max_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2020-05-11 21:16:02,586 loading file model-saves/final-model.pt\n[4 (0.9463609457015991)] [0 (0.8664907813072205)]\n"
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "classifier = TextClassifier.load('model-saves/final-model.pt')\n",
    "\n",
    "pos_sentence = Sentence(preprocess('I love Python!'))\n",
    "neg_sentence = Sentence(preprocess('Python is the worst!'))\n",
    "\n",
    "classifier.predict(pos_sentence)\n",
    "classifier.predict(neg_sentence)\n",
    "\n",
    "print(pos_sentence.labels, neg_sentence.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitbaseconda569edf27ad0243b9aa6880a18fbf0a13",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}